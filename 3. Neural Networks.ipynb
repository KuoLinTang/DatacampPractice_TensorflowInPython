{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80043b67",
   "metadata": {},
   "source": [
    "# Dense layers\n",
    "\n",
    "![](Image/Image8.jpg)\n",
    "\n",
    "Dense layers 代表這個 layer 上的所有 nodes 都和前一個 layer 的所有 nodes 互相連接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e207eb",
   "metadata": {},
   "source": [
    "## 例子\n",
    "\n",
    "![](Image/Image9.jpg)\n",
    "\n",
    "0.5 沒有 weight，表示是 bias。1 和 35 都是 inputs\n",
    "\n",
    "\n",
    "**一個簡單的 densed neural network 的程式，有兩種做法：**\n",
    "\n",
    "1. 利用矩陣乘法來計算 outputs (較底層 low level)\n",
    "2. 利用 tensorflow 既有的 keras.layers.Dense 函數來實踐 (較頂層 high level)\n",
    "\n",
    "![](Image/Image11.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3066f5e",
   "metadata": {},
   "source": [
    "**方法一**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c74e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# define input\n",
    "inputs = tf.constant([[1.0, 35.0]])\n",
    "\n",
    "# define weights\n",
    "weights = tf.Variable([[-0.05], [-0.01]])\n",
    "\n",
    "# define bias\n",
    "bias = tf.Variable([0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f7d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply inputs (features) by the weights\n",
    "products = tf.matmul(inputs, weights)    # 用矩陣乘法來求 inputs 和 weights 的內積\n",
    "\n",
    "# add products with the bias\n",
    "values = products + bias\n",
    "\n",
    "# define dense layer with a activation function (sigmoid function)\n",
    "dense = tf.keras.activations.sigmoid(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539d9e6",
   "metadata": {},
   "source": [
    "**方法二**\n",
    "\n",
    "多層 hidden layers\n",
    "\n",
    "![](Image/Image10.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811568ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input layer\n",
    "inputs = tf.constant([[1.0, 35.0]])\n",
    "\n",
    "# define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(5, activation='sigmoid')(dense1)\n",
    "\n",
    "# define output layer\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabc6b2",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "\n",
    "有三個常用的 activation functions：\n",
    "\n",
    "1. Sigmoid function\n",
    "2. Relu\n",
    "3. Softmax\n",
    "\n",
    "### Sigmoid functions\n",
    "![](Image/Image12.jpg)\n",
    "\n",
    "主要用在 **binary** classification problems 的 output layer。\n",
    "\n",
    "當使用 low level approach (linear algebra) 時，要用 tf.keras.activations.sigmoid() <br/>\n",
    "當使用 high level approach (既有的 dense function) 時，要在 tf.keras.layers.Dense() 中 specify \"sigmoid\"\n",
    "\n",
    "\n",
    "### Relu functions (Rectified linear unit)\n",
    "![](Image/Image13.jpg)\n",
    "\n",
    "通常在 output layer 以外的其他 layers (hidden layers) 中使用。\n",
    "\n",
    "當使用 low level approach (linear algebra) 時，要用 tf.keras.activations.relu() <br/>\n",
    "當使用 high level approach (既有的 dense function) 時，要在 tf.keras.layers.Dense() 中 specify \"relu\"\n",
    "\n",
    "\n",
    "### Softmax functions\n",
    "\n",
    "主要用在 **multi-class** classification problems 的 output layer。可以計算 multiclass 的 probabilities。\n",
    "\n",
    "當使用 low level approach (linear algebra) 時，要用 tf.keras.activations.softmax() <br/>\n",
    "當使用 high level approach (既有的 dense function) 時，要在 tf.keras.layers.Dense() 中 specify \"softmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf75ef",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "\n",
    "有三種常用的 optimizers (minimisers)：\n",
    "\n",
    "1. SGD (Stochastic)\n",
    "2. RMS\n",
    "3. Adam\n",
    "\n",
    "![](Image/Image14.jpg)\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "是一種 improved gradient descent ，較不容易停在 local minima。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13017a52",
   "metadata": {},
   "source": [
    "## Tensorflow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20740274",
   "metadata": {},
   "source": [
    "### SGD\n",
    "Learning rate 在訓練過程中是固定的，必須測試不同的 learning rates。如果 rate 太大，則下降速度快，但可能會跳過 global minima。\n",
    "\n",
    "程式碼：tf.keras.optimizers.SGD(learning_rate)，learning_rate 為最重要的參數。\n",
    "\n",
    "### RMS\n",
    "不同的 features 的 learning rates 是不同的，因此當 features 數量很多的時候用 RMS 比較合理\n",
    "\n",
    "程式碼：tf.keras.optimizers.RMSprop(learning_rate, momentum, decay)，有 learning_rate, momentum, decay 三個重要參數。\n",
    "\n",
    "Momentum 就是運動量的意思，可以優化學習的速度。在同方向上的學習速度會變快，方向改變時學習速度變慢。\n",
    "\n",
    "### Adam\n",
    "提供更方便且簡單的選擇。\n",
    "\n",
    "相似於 RMS，可以透過指定 beta1 這個參數來調整 momentum 和 decay。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8076e03",
   "metadata": {},
   "source": [
    "## 建立一個 neural network 的程式碼演示\n",
    "\n",
    "使用 credict card 的資料，包含 marital status, payment amount 等等 features 來預測 default 這個變數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1217b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
      "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
      "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
      "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
      "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
      "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
      "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
      "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
      "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
      "0       0.0       0.0       0.0                           1  \n",
      "1    1000.0       0.0    2000.0                           1  \n",
      "2    1000.0    1000.0    5000.0                           0  \n",
      "3    1100.0    1069.0    1000.0                           0  \n",
      "4    9000.0     689.0     679.0                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(30000, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "credict = pd.read_csv(\"Datasets/uci_credit_card.csv\")\n",
    "print(credict.head())\n",
    "print(credict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9caf0d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 2. ... 2. 1. 1.]\n",
      "[[    0.   689.     0.     0.     0.     0.]\n",
      " [    0.  1000.  1000.  1000.     0.  2000.]\n",
      " [ 1518.  1500.  1000.  1000.  1000.  5000.]\n",
      " ...\n",
      " [    0.     0. 22000.  4200.  2000.  3100.]\n",
      " [85900.  3409.  1178.  1926. 52964.  1804.]\n",
      " [ 2078.  1800.  1430.  1000.  1000.  1000.]]\n",
      "[ True  True False ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "marriage = np.array(credict[\"MARRIAGE\"], dtype = np.float32)\n",
    "payment_amount = np.array(credict[[\"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]], dtype = np.float32)\n",
    "target = np.array(credict['default.payment.next.month'], dtype = np.bool)\n",
    "\n",
    "print(marriage)\n",
    "print(payment_amount)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c10dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "def model(bias, weights, features):\n",
    "    return tf.keras.activations.sigmoid(tf.matmul(features, weights) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee9ecb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "def loss_function(bias, weights, features, targets):\n",
    "    predictions = model(bias, weights, features)\n",
    "    return tf.keras.lossess.binary_crossentropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da9e454",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[0] mismatch In[1] shape: 6 vs. 2: [30000,6] [2,1] 0 0 [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3e1b8df6d1aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# initialise the optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpayment_amount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \"\"\"\n\u001b[1;32m--> 520\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    521\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e1b8df6d1aa>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# initialise the optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpayment_amount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-12a6d7689aa1>\u001b[0m in \u001b[0;36mloss_function\u001b[1;34m(bias, weights, features, targets)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define the loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlossess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-3b877cebad58>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(bias, weights, features)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define neural network model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3652\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[0;32m   3653\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3654\u001b[1;33m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[0;32m   3655\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0;32m   3656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5693\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5694\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5695\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5696\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5697\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: In[0] mismatch In[1] shape: 6 vs. 2: [30000,6] [2,1] 0 0 [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "# initialise the optimizer\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate = 0.01, momentum = 0.9)\n",
    "opt.minimize(lambda: loss_function(bias, weights, payment_amount, target), var_list = [bias, weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2995810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測最後的結果\n",
    "final_predictions = model(bias, weights, features)\n",
    "\n",
    "# 比較最後的結果 (binary classification problems 使用 confusion matrix)\n",
    "confusion_matrix(target, final_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c501138",
   "metadata": {},
   "source": [
    "# Training a network in Tensorflow 可能的問題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47825e44",
   "metadata": {},
   "source": [
    "## Initialisation\n",
    "當函數的變數非常多的時候，如何指定 initial values 是個大問題。如果沒有選擇好的初始值，則容易卡在 local minima。\n",
    "\n",
    "一般來說，最簡單的方法是利用 ones() 將所有變數初始化成 1。然而，這不是個好方法，因為各個函數的數量極並不是一樣的。有些可能極度小，有些可能非常大。因此，有一個方法，是用隨機方式產生變數的初始值。\n",
    "\n",
    "隨機的方式為在以下的隨機分布中選取數值：\n",
    "\n",
    "1. Normal distribution\n",
    "2. Uniform distribution\n",
    "3. Glorot Initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd4f0a",
   "metadata": {},
   "source": [
    "### Normal distribution 的 random initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51bb2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7014304  -0.8746814  -0.81709063 ... -1.4385091   1.6383195\n",
      "   0.4407463 ]\n",
      " [-2.1260412   0.7946293  -0.11950668 ... -0.8268652  -0.31346998\n",
      "  -1.7032689 ]\n",
      " [-0.06066773  0.32732207  0.8462351  ... -1.0806044  -1.5447717\n",
      "   0.19221427]\n",
      " ...\n",
      " [ 1.7832956   0.1683405   0.29741174 ... -0.38904557 -1.1219796\n",
      "   1.2069103 ]\n",
      " [ 2.2026093   1.475204   -0.7525437  ... -1.2041426  -1.4553659\n",
      "   0.48045155]\n",
      " [-1.3937607  -2.1176517   0.99334973 ...  1.340453    0.86729145\n",
      "   1.4102954 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# random normal variables\n",
    "weights = tf.Variable(tf.random.normal([500, 500]))\n",
    "print(weights.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3c637",
   "metadata": {},
   "source": [
    "### Truncated normal distribution 的 random initial values\n",
    "Truncated normal values 會丟棄極度小或極度大的數值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80f5d928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.75754523 -0.6946054  -0.14187825 ... -0.03918338  0.11052865\n",
      "  -0.8736046 ]\n",
      " [ 0.48655966 -1.4691384  -0.392127   ... -0.4000593  -0.06665671\n",
      "  -0.48048642]\n",
      " [ 1.1485841   0.18432872  0.61014235 ... -0.8369745   0.6632963\n",
      "  -0.92996764]\n",
      " ...\n",
      " [-0.07028735 -0.13742907 -0.13226186 ... -0.45888528 -1.4815992\n",
      "   0.21029063]\n",
      " [ 0.19020243 -0.12102135  0.6180326  ...  0.08958569 -1.1149473\n",
      "   1.2662982 ]\n",
      " [-0.786944    0.7597877   0.74569905 ...  0.817365   -0.62463707\n",
      "  -1.8402792 ]]\n"
     ]
    }
   ],
   "source": [
    "# truncated random normal variables\n",
    "weights2 = tf.Variable(tf.random.truncated_normal([500, 500]))\n",
    "print(weights2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a908d8",
   "metadata": {},
   "source": [
    "### High level method\n",
    "\n",
    "![](Image/Image15.jpg)\n",
    "\n",
    "可以在 tf.keras.layers.Dense() 裡面傳入 kernel_initializer 這個參數來初始化 weights。如果沒有傳入任何有關 initialisation 的參數，則 default initializer 就是 Glorot Initializer。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433981e7",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Training 的時候，過擬合的模型會太過符合 training data，導致 variance 高 (bias 低)。如下圖：\n",
    "\n",
    "![](Image/Image16.jpg)\n",
    "\n",
    "Testing 的時候，過擬合的模型因為太符合 training data，導致預測值與實際數值反而差很多，造成 **Out-of-sample** 的預測失準。如下圖：\n",
    "\n",
    "![](Image/Image17.jpg)\n",
    "\n",
    "解決過擬合的方式有：\n",
    "\n",
    "1.  Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4aecb1",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "隨機將 neural network 中的幾個 edges (連接 nodes 的線) 丟掉，讓模型不要那麼複雜。這樣可以讓模型不會太過依賴某些 nodes 的數值，導致太依賴某些 training data 的結果。如下圖：\n",
    "\n",
    "![](Image/Image18.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c9ad20",
   "metadata": {},
   "source": [
    "### Implement Dropout in a network (演示)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b27d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# define inputs\n",
    "inputs = np.array(credict[[\"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb451007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dense layer 1\n",
    "dense1 = tf.keras.layers.Dense(32, activation = \"relu\")(inputs) \n",
    "\n",
    "# define dense layer 2\n",
    "dense2 = tf.keras.layers.Dense(16, activation = \"relu\")(dense1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659286d",
   "metadata": {},
   "source": [
    "在將數值傳回 output layer 之前，加上 dropout layers (drop 25% 的 edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744ed2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dropout\n",
    "Dropout1 = tf.keras.layers.Dropout(0.25)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af4d3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output layer\n",
    "outputs = tf.keras.layers.Dense(1, activation = \"sigmoid\")(Dropout1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
